#!/bin/bash
[ -z "$1"          ] && SCHEDULER="SLURM" || SCHEDULER="$1"
[ -z "$2"          ] && QUEUE="normal"   || QUEUE="$2"
[ -z "$3"          ] && ACCOUNT="ch4"     || ACCOUNT="$3"
[ -z "$4"          ] && WAITFORJOB=""     || WAITFORJOB="$4"

if [ -z "$4" ]; then
  WAITFORJOB=""
else
  WAITFORJOB="$4"
fi


cat > job <<EOF_job
#!/bin/bash -l
#
#SBATCH --job-name=x_chain
#SBATCH --output=job.out
#SBATCH --time=00:15:00
#SBATCH --nodes=1
#SBATCH --partition=normal
#SBATCH --account=${ACCOUNT}
module unload xalt

### !!!! specific to user robro !!!!
conda activate py3-cscs
#### !!!!!!!!!!!!!!!!!!!!!!!!!!!!!

cd ..
python control_simulation.py
exit_status=\$?
echo 'exit_status:' \$exit_status
if [ "\${exit_status}" -eq 0 ]
then
    echo "Ready to run "
    ./run_daint.sh
	jobidc=\$(sbatch compress.bash ./output/lm_c)
	jobidf=\$(sbatch compress.bash ./output/lm_f)
	unset SLURM_MEM_PER_CPU
	sbatch --dependency=afterany:\${jobidc##* } movehook.bash ./output/lm_c lm_c
	sbatch --dependency=afterany:\${jobidf##* } movehook.bash ./output/lm_f lm_f
else
    echo "errors in control_simulation. Aborting step"
fi
EOF_job

if [ -z "${WAITFORJOB}" ]; then
  jobid=`sbatch -C gpu job | sed 's/Submitted batch job //g'`
else
  jobid=`sbatch -C gpu --dependency=afterany:${WAITFORJOB} job | sed 's/Submitted batch job //g'`
fi
#jobid=`sbatch -C gpu job | sed 's/Submitted batch job //g'`

if [ $? -eq 0 -a -n "${jobid}" ]; then
  echo "${jobid}" > .jobid
  echo "${jobid}"
else
  exit 1
fi
